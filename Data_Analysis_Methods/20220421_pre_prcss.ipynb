{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리\n",
    "===\n",
    "(정규화, 로그 변환, 스케일러, 원-핫 인코딩)\n",
    "---\n",
    "* 선형회귀 모델을 위한 데이터 변환\n",
    "    - 회귀 모델과 같은 선형 모델은 일반적으로 피처와 타깃값 간에 선형의 관계가 있다고 가정하고, 이러한 최적의 선형함수를 찾아내 결과를 예측함.\n",
    "    - 또한 선형 회귀 모델은 피처값과 타깃값의 분포가 정규 분포 형태인 경우를 매우 선호함.\n",
    "### 로그 변환, 스케일러, 다항 특성 적용\n",
    "\n",
    "<table>\n",
    " <tr>\n",
    "    <th>변환대상</th>\n",
    "    <th>설명</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>타깃값 변환</td>\n",
    "    <td>회귀에서 타깃값은 반드시 정규 분포를 가져야 함.</br>\n",
    "    이를 위해 주로 로그변환을 적용.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"3\">피처값 변환</td>\n",
    "    <td>StandardScaler : 평균이 0, 분산이 1인 표준정규분포를 가진 데이터 세트로 변환</br>\n",
    "    MinMaxScaler : 최솟값이 0, 최댓값이 1인 값으로 정규화를 수행\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>스케일링/정규화를 수행한 데이터 세트에 다시 다항 특성을 적용하여 변환.</br>\n",
    "    보통 1번 방법을 통해 예측 성능에 향상이 없을 경우 이와 같은 방법을 적용.\n",
    "    </td>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>원래 값에 log 함수를 적용하면 보다 정규 분포에 가까운 형태로 값이 분포됨. 로그 변환은 매우 유용한 변환이며, 실제로 선형 회귀에서는 앞의 1, 2번 방법보다 로그 변환이 훨씬 많이 사용되는 변환 방법.</br>\n",
    "    왜냐하면 1번 방법의 경우 예측 성능 향상을 크게 기대하기 어려운 경우가 많으며, 2번 방법의 경우 피처의 개수가 매우 많을 경우에는 다항 변환으로 생성되는 피처의 개수가 기하급수적으로 늘어나 과적합 이슈가 발생할 수 있기 때문.\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "### 인코딩\n",
    "* 선형 회귀의 데이터 인코딩은 일반적으로 레이블 인코딩이 아닌 원-핫 인코딩을 적용함.\n",
    "* 레이블 인코딩 : 카테고리 별로 1, 2, 3, 4, ...\n",
    "* 원-핫 인코딩 : 0과 1로 구성된 행렬 형태\n",
    "\n",
    "#### 실습 : 피처 데이터 변환에 따른 예측 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 21.,  55.,  82., 154.,  84.,  41.,  30.,   8.,  10.,  21.]),\n",
       " array([ 5. ,  9.5, 14. , 18.5, 23. , 27.5, 32. , 36.5, 41. , 45.5, 50. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "house_price = load_boston()\n",
    "X_data = house_price.data\n",
    "y_target = house_price.target\n",
    "\n",
    "print(y_target.shape)\n",
    "plt.hist(y_target, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method는 표준 정규 분포 변환(Standard), 최대값/최소값 정규화(MinMax), 로그변환(Log) 결정\n",
    "# p_degree는 다항식 특성을 추가할 때 적용, p_degree는 2이상 부여하지 않음.\n",
    "def get_scaled_data(method=\"None\", p_degree=None, input_data=None) :\n",
    "    if method == \"Standard\" :\n",
    "        scaled_data = StandardScaler().fit_transform(input_data)\n",
    "        # 정규분포화\n",
    "    elif method == \"MinMax\" :\n",
    "        scaled_data = MinMaxScaler().fit_transform(input_data)\n",
    "        # 최대최소\n",
    "    elif method == \"Log\" :\n",
    "        scaled_data = np.log1p(input_data)\n",
    "        # 로그변환\n",
    "    else :\n",
    "        scaled_data = input_data\n",
    "        # 메소드 입력 안 했을 경우 그대로 저장.\n",
    "\n",
    "    if p_degree != None :\n",
    "        scaled_data = PolynomialFeatures(\n",
    "            degree=p_degree, include_bias=False).fit_transform(scaled_data)\n",
    "        # p_degree 있는 경우 Polynomial 진행\n",
    "    \n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "def get_linear_reg_eval(method=\"Ridge\", params=[], X_data_n=None, y_target_n=None, verbose=True) :\n",
    "    sub_data = []\n",
    "    for param in params :        \n",
    "        ridge = Ridge(alpha=param)\n",
    "        neg_mse_scores = cross_val_score(ridge, X_data_n, y_target_n, scoring=\"neg_mean_squared_error\", cv=5, verbose=verbose)\n",
    "        rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
    "        avg_rmse = np.mean(rmse_scores)\n",
    "        print(f\"alpha {param}일 때 5 folds의 개별 평균 RMSE : {avg_rmse:.4f}\")\n",
    "        sub_data.append(np.round(avg_rmse,3))\n",
    "    data.append(sub_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 변환 유형:None, Polynomial Degree:None\n",
      "alpha 0.1일 때 5 folds의 개별 평균 RMSE : 5.7885\n",
      "alpha 1일 때 5 folds의 개별 평균 RMSE : 5.6526\n",
      "alpha 10일 때 5 folds의 개별 평균 RMSE : 5.5182\n",
      "alpha 100일 때 5 folds의 개별 평균 RMSE : 5.3296\n",
      "\n",
      "## 변환 유형:Standard, Polynomial Degree:None\n",
      "alpha 0.1일 때 5 folds의 개별 평균 RMSE : 5.8260\n",
      "alpha 1일 때 5 folds의 개별 평균 RMSE : 5.8029\n",
      "alpha 10일 때 5 folds의 개별 평균 RMSE : 5.6368\n",
      "alpha 100일 때 5 folds의 개별 평균 RMSE : 5.4214\n",
      "\n",
      "## 변환 유형:Standard, Polynomial Degree:2\n",
      "alpha 0.1일 때 5 folds의 개별 평균 RMSE : 8.8272\n",
      "alpha 1일 때 5 folds의 개별 평균 RMSE : 6.8713\n",
      "alpha 10일 때 5 folds의 개별 평균 RMSE : 5.4849\n",
      "alpha 100일 때 5 folds의 개별 평균 RMSE : 4.6344\n",
      "\n",
      "## 변환 유형:MinMax, Polynomial Degree:None\n",
      "alpha 0.1일 때 5 folds의 개별 평균 RMSE : 5.7636\n",
      "alpha 1일 때 5 folds의 개별 평균 RMSE : 5.4650\n",
      "alpha 10일 때 5 folds의 개별 평균 RMSE : 5.7542\n",
      "alpha 100일 때 5 folds의 개별 평균 RMSE : 7.6349\n",
      "\n",
      "## 변환 유형:MinMax, Polynomial Degree:2\n",
      "alpha 0.1일 때 5 folds의 개별 평균 RMSE : 5.2976\n",
      "alpha 1일 때 5 folds의 개별 평균 RMSE : 4.3227\n",
      "alpha 10일 때 5 folds의 개별 평균 RMSE : 5.1852\n",
      "alpha 100일 때 5 folds의 개별 평균 RMSE : 6.5379\n",
      "\n",
      "## 변환 유형:Log, Polynomial Degree:None\n",
      "alpha 0.1일 때 5 folds의 개별 평균 RMSE : 4.7704\n",
      "alpha 1일 때 5 folds의 개별 평균 RMSE : 4.6762\n",
      "alpha 10일 때 5 folds의 개별 평균 RMSE : 4.8364\n",
      "alpha 100일 때 5 folds의 개별 평균 RMSE : 6.2409\n"
     ]
    }
   ],
   "source": [
    "# Ridge의 alpha값을 다르게 적용하고 다양한 데이터 변환방법에 따른 RMSE 추출.\n",
    "alphas = [0.1, 1, 10, 100]\n",
    "\n",
    "# 변환 방법은 모두 6개, 원본 그대로, 표준정규분포, 표준정규분포+다항식 특성\n",
    "# 최대/최소 정규화, 최대/최소 정규화+다항식 특성, 로그변환\n",
    "scale_methods=[(None, None), (\"Standard\", None), (\"Standard\", 2),\n",
    "                (\"MinMax\", None), (\"MinMax\", 2), (\"Log\", None)]\n",
    "\n",
    "for scale_method in scale_methods :\n",
    "    X_data_scaled = get_scaled_data(method=scale_method[0], p_degree=scale_method[1],\n",
    "                                    input_data=X_data)\n",
    "    print(f\"\\n## 변환 유형:{scale_method[0]}, Polynomial Degree:{scale_method[1]}\")\n",
    "\n",
    "    # alpha 값에 따른 회귀 모델의 폴드 평균 RMSE를 출력하고,\n",
    "    # 회귀 계수값들을 DataFrame으로 반환해주는 함수\n",
    "    get_linear_reg_eval(\"Ridge\", params=alphas, X_data_n=X_data_scaled,\n",
    "                        y_target_n=y_target, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">alpha값</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>alpha=0.1</th>\n",
       "      <th>alpha=1</th>\n",
       "      <th>alpha=10</th>\n",
       "      <th>alpha=100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>변환유형</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>원본데이터</th>\n",
       "      <td>5.788</td>\n",
       "      <td>5.653</td>\n",
       "      <td>5.518</td>\n",
       "      <td>5.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>표준정규분포</th>\n",
       "      <td>5.826</td>\n",
       "      <td>5.803</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>표준정규분포 + 2차 다항식</th>\n",
       "      <td>8.827</td>\n",
       "      <td>6.871</td>\n",
       "      <td>5.485</td>\n",
       "      <td>4.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>최솟값/최댓값 정규화</th>\n",
       "      <td>5.764</td>\n",
       "      <td>5.465</td>\n",
       "      <td>5.754</td>\n",
       "      <td>7.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>최솟값/최댓값 정규화 + 2차 다항식</th>\n",
       "      <td>5.298</td>\n",
       "      <td>4.323</td>\n",
       "      <td>5.185</td>\n",
       "      <td>6.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>로그변환</th>\n",
       "      <td>4.770</td>\n",
       "      <td>4.676</td>\n",
       "      <td>4.836</td>\n",
       "      <td>6.241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        alpha값                           \n",
       "                     alpha=0.1 alpha=1 alpha=10 alpha=100\n",
       "변환유형                                                     \n",
       "원본데이터                    5.788   5.653    5.518     5.330\n",
       "표준정규분포                   5.826   5.803    5.637     5.421\n",
       "표준정규분포 + 2차 다항식          8.827   6.871    5.485     4.634\n",
       "최솟값/최댓값 정규화              5.764   5.465    5.754     7.635\n",
       "최솟값/최댓값 정규화 + 2차 다항식     5.298   4.323    5.185     6.538\n",
       "로그변환                     4.770   4.676    4.836     6.241"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(data, columns=[[\"alpha값\", \"alpha값\", \"alpha값\", \"alpha값\"], [\"alpha=0.1\", \"alpha=1\", \"alpha=10\", \"alpha=100\"]])\n",
    "result_df[\"변환유형\"] = [\"원본데이터\", \"표준정규분포\", \"표준정규분포 + 2차 다항식\", \"최솟값/최댓값 정규화\", \"최솟값/최댓값 정규화 + 2차 다항식\", \"로그변환\"]\n",
    "result_df.set_index(\"변환유형\", inplace=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀\n",
    "### 로지스틱 회귀 개요\n",
    "* 로지스틱 회귀는 선형 회귀 방식을 분류에 적용한 알고리즘. 즉, 로지스틱 회귀는 분류에 사용됨.       \n",
    "로지스틱 회귀가 선형 회귀와 다른 점은 학습을 통해 선형 함수의 회귀 최적선을 찾는 것이 아니라, 시그모이드(Sigmoid)함수 최적선을 찾고, 이 시그모이드 함수의 반환 값을 확률로 간주해 확률에 따라 분류를 결정함.\n",
    "* 로지스틱 회귀는 주로 이진분류에 사용됨(다중 클래스 분류에도 적용 가능함).     \n",
    "  로지스틱 회귀에서 예측 값은 예측 확률을 의미하며, 예측 확률이 0.5 이상이면 1로, 0.5 이하이면 0으로 예측함. 로지스틱 회귀의 예측 확률은 시그모이드 함수의 출력값으로 계산됨.   \n",
    "<img src=\"C:/Users/user/Desktop/Vocational_Training/FinTech/images/functions_graph.png\" width=\"40%\">\n",
    "\n",
    "#### 로지스틱 회귀 예측\n",
    "\n",
    "* 시그모이드 함수 : $y = \\frac{1}{1+e^{-x}}$\n",
    "* 단순 선형회귀 : $y=w_1x + w_0$가 있다고 할 때,    \n",
    "  로지스틱 회귀는 0과 1을 예측하기에 단순 회귀식은 의미가 없음.    \n",
    "  하지만 Odds(성공확률/실패확률)을 통해 선형 회귀식에 확률을 적용할 수 있음.\n",
    "  $$Odds(p) = \\frac{p}{1-p}$$ \n",
    "  하지만 확률p의 범위가 (0,1)이므로 선형 회귀의 반환값인 $(-\\infty, +\\infty)$에 대응하기 위해 로그 변환을 수행하고 이 값에 대해 선형 회귀를 적용함.    \n",
    "  $$\\log{Odds(p)} = w_1x + w_0$$\n",
    "  해당 식을 데이터 값 x의 확률 p로 정리하면 아래와 같음\n",
    "  $$p(x)=\\frac{1}{1+e^{-(w_1x+w_0)}}$$\n",
    "  로지스틱 회귀는 학습을 통해 시그모이드 함수의 w를 최적화하여 예측하는 것.\n",
    "\n",
    "#### 시그모이드를 이용한 로지스틱 회귀 예측\n",
    "\n",
    "<img src=\"C:/Users/user/Desktop/Vocational_Training/FinTech/images/Sigmoid.png\" width=\"40%\">\n",
    "\n",
    "* 로지스틱 회귀는 가볍고 빠르지만, 이진 분류 예측 성능도 뛰어남. 이 때문에 로지스틱 회귀를 이진 분류의 기본 모델로 사용하는 경우가 많음. 또한 로지스틱 회귀는 희소한 데이터 세트 분류에도 뛰어난 성능을 보여서 텍스트 분류에서도 자주 사용됨.\n",
    "* 사이킷런은 LogisticRegression 클래스로 로지스틱 회귀를 구현함. 주요 하이퍼 파라미터로 penalty와 C가 있음. Penalty는 Regularization의 유형을 설정함. 'l2'로 설정시 L2 규제 등. default는 'l2'. C는 규제 강도를 조절하는 alpha값의 역수. C값이 작을수록 규제 강도가 큼.   \n",
    "$$C=\\frac{1}{\\alpha}$$\n",
    "\n",
    "\n",
    "  #### 실습 : 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 위스콘신 유방암 데이터 불러오기\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# StandardScaler()로 평균이 0, 분산 1로 데이터 분포도 변환\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cancer.data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_scaled, cancer.target, test_size=0.3, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.977\n",
      "roc_auc 0.972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 로지스틱 회귀를 이용하여 학습 및 예측 수행\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "lr_preds = lr_clf.predict(X_test)\n",
    "\n",
    "# accuracy와 roc_auc 측정\n",
    "print(f\"accuracy {accuracy_score(y_test, lr_preds):.3f}\")\n",
    "print(f\"roc_auc {roc_auc_score(y_test, lr_preds):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터 : {'C': 1, 'penalty': 'l2'}, 최적 평균 정확도 : 0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"penalty\" : [\"l2\", \"l1\"],\n",
    "    \"C\" :[0.01, 0.1, 1, 1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_clf = GridSearchCV(lr_clf, param_grid=params, scoring=\"accuracy\", cv=3)\n",
    "grid_clf.fit(data_scaled, cancer.target)\n",
    "print(f\"최적 하이퍼 파라미터 : {grid_clf.best_params_}, 최적 평균 정확도 : {grid_clf.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 트리\n",
    "### 회귀 트리 개요\n",
    "* 회귀 트리 : 트리 기반의 회귀 방식\n",
    "* 사이킷런의 결정 트리 및 결정 트리 기반의 앙상블 알고리즘 분류 뿐만 아니라 회귀도 가능.\n",
    "* 트리가 CART(Classification And Regression Trees)를 기반으로 만들어졌기 때문.   \n",
    " CART는 분류 뿐만 아니라 회귀도 가능한 트리 분할 알고리즘.\n",
    "* CART 회귀 트리는 분류와 유사하게 분할을 하며, 분할 기준은 RSS(SSE)가 최소가 될 수 있는 기준을 찾아 분할됨.\n",
    "* 최종 분할이 완료된 후에 각 분할 영역에 있는 데이터 결정값들의 평균 값으로 학습/예측함.   \n",
    "<img src=\"C:/Users/user/Desktop/Vocational_Training/FinTech/images/CART.png\" width=\"40%\">\n",
    "\n",
    "### 회귀 트리의 오버피팅(과대적합)\n",
    "* 회귀 트리 역시 복잡한 트리 구조를 가질 경우 오버피팅하기 쉬움. 트리의 크기와 노드 개수의 제한 등의 방법을 통해 오버 피팅을 개선 할 수 있음.   \n",
    "<img src=\"C:/Users/user/Desktop/Vocational_Training/FinTech/images/CART_overfitting.png\" width=\"40%\">\n",
    "\n",
    "#### 실습 : 회귀 트리로 보스턴 집값 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 교차 검증의 개별 Negative MSE scores : [ -7.88 -13.14 -20.57 -46.23 -18.88]\n",
      "5 교차 검증의 개별 RMSE scores : [2.81 3.63 4.54 6.8  4.34]\n",
      "5 교차 검증의 평균 RMSE : 4.423\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 보스턴 데이터 세트 로드\n",
    "boston = load_boston()\n",
    "bostonDF = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "\n",
    "# 랜덤 포레스트로 교차 검증\n",
    "bostonDF[\"PRICE\"] = boston.target\n",
    "y_target = bostonDF[\"PRICE\"]\n",
    "X_data = bostonDF.drop([\"PRICE\"], axis=1, inplace=False)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "neg_mse_scores = cross_val_score(rf, X_data, y_target, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "rmse_scores = np.sqrt(-1*neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "print(f\"5 교차 검증의 개별 Negative MSE scores : {np.round(neg_mse_scores,2)}\")\n",
    "print(f\"5 교차 검증의 개별 RMSE scores : {np.round(rmse_scores,2)}\")\n",
    "print(f\"5 교차 검증의 평균 RMSE : {np.round(avg_rmse,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_cv_prediction(model=None, X_data=None, y_target=None) :\n",
    "    neg_mse_scores = cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "    rmse_scores = np.sqrt(-1*neg_mse_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    if model == dt_reg :\n",
    "        print(f\"### DecisionTreeRegressor ### \\n5 교차 검증의 평균 RMSE : {np.round(avg_rmse,3)}\")\n",
    "    elif model == rf_reg :\n",
    "        print(f\"### RandomForestRegressor ### \\n5 교차 검증의 평균 RMSE : {np.round(avg_rmse,3)}\")\n",
    "    else :\n",
    "        print(f\"### XGBRegressor ### \\n5 교차 검증의 평균 RMSE : {np.round(avg_rmse,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### DecisionTreeRegressor ### \n",
      "5 교차 검증의 평균 RMSE : 5.978\n",
      "### RandomForestRegressor ### \n",
      "5 교차 검증의 평균 RMSE : 4.423\n",
      "### XGBRegressor ### \n",
      "5 교차 검증의 평균 RMSE : 4.251\n"
     ]
    }
   ],
   "source": [
    "# 3개 회귀 트리 모델로 회귀 수행\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# max_depth=4짜리 디시전 트리\n",
    "dt_reg = DecisionTreeRegressor(random_state=0, max_depth=4)\n",
    "# n_estimators=1000짜리 랜덤 포레스트\n",
    "rf_reg = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "# n_estimators=1000짜리 XGBoost\n",
    "xg_reg = XGBRegressor(num_round=1000, verbosity=0)\n",
    "\n",
    "# 트리 기반의 회귀 모델을 반복하면서 평가 수행\n",
    "models = [dt_reg, rf_reg, xg_reg]\n",
    "for model in models :\n",
    "    get_model_cv_prediction(model, X_data, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 회귀 트리는 feature_importances_로 피처 중요도를 파악한다.\n",
    "# 선형회귀의 회귀 계수 역할을 함.\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "rf_reg = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "\n",
    "# 앞 예제에서 만들어진 X_data, y_target 데이터 셋을 적용하여 학습함.\n",
    "rf_reg.fit(X_data, y_target)\n",
    "\n",
    "feature_series = pd.Series(data=rf_reg.feature_importances_, index=X_data.columns)\n",
    "feature_series = feature_series.sort_values(ascending=False)\n",
    "sns.barplot(x=feature_series, y=feature_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "xg_reg = XGBRegressor(num_round=1000, verbosity=0)\n",
    "\n",
    "# 앞 예제에서 만들어진 X_data, y_target 데이터 셋을 적용하여 학습함.\n",
    "xg_reg.fit(X_data, y_target)\n",
    "\n",
    "feature_series = pd.Series(data=xg_reg.feature_importances_, index=X_data.columns)\n",
    "feature_series = feature_series.sort_values(ascending=False)\n",
    "sns.barplot(x=feature_series, y=feature_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_ftrs_rf = [\"RM\", \"LSTAT\", \"DIS\", \"CRIM\", \"NOX\"]\n",
    "impt_ftrs_xg = [\"LSTAT\", \"RM\", \"NOX\", \"DIS\", \"PTRATIO\"]\n",
    "\n",
    "X_data_rf = X_data[impt_ftrs_rf]\n",
    "X_data_xg = X_data[impt_ftrs_xg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### DecisionTreeRegressor ### \n",
      "5 교차 검증의 평균 RMSE : 5.75\n",
      "### RandomForestRegressor ### \n",
      "5 교차 검증의 평균 RMSE : 4.586\n",
      "### XGBRegressor ### \n",
      "5 교차 검증의 평균 RMSE : 4.934\n"
     ]
    }
   ],
   "source": [
    "# max_depth=4짜리 디시전 트리\n",
    "dt_reg = DecisionTreeRegressor(random_state=0, max_depth=4)\n",
    "# n_estimators=1000짜리 랜덤 포레스트\n",
    "rf_reg = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "# n_estimators=1000짜리 XGBoost\n",
    "xg_reg = XGBRegressor(num_round=1000, verbosity=0)\n",
    "\n",
    "# 트리 기반의 회귀 모델을 반복하면서 평가 수행\n",
    "# rf에서 뽑힌 주요 피처 상위 5개 항목 평가\n",
    "models = [dt_reg, rf_reg, xg_reg]\n",
    "for model in models :\n",
    "    get_model_cv_prediction(model, X_data_rf, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### DecisionTreeRegressor ### \n",
      "5 교차 검증의 평균 RMSE : 5.48\n",
      "### RandomForestRegressor ### \n",
      "5 교차 검증의 평균 RMSE : 4.512\n",
      "### XGBRegressor ### \n",
      "5 교차 검증의 평균 RMSE : 4.709\n"
     ]
    }
   ],
   "source": [
    "# xgb에서 뽑힌 주요 피처 상위 5개 항목 평가\n",
    "models = [dt_reg, rf_reg, xg_reg]\n",
    "for model in models :\n",
    "    get_model_cv_prediction(model, X_data_xg, y_target)\n",
    "\n",
    "# 예상과 달리 XGB에서 중요 피처의 RMSE 값이 떨어짐."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d240ba0dc525c389faa33f5dcce5b4f32b6d6aa6d70d6d2dd929bd2b09ab69f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
