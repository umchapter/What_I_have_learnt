{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv(\"./csv_data/titanic_train.csv\")\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### train 데이터 정보 ### \\n\")\n",
    "print(titanic_df.info())    #891 개 중에 null 갯수 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[\"Age\"].fillna(titanic_df[\"Age\"].mean(), inplace=True)\n",
    "titanic_df[\"Cabin\"].fillna(\"N\", inplace=True)\n",
    "titanic_df[\"Embarked\"].fillna(\"N\", inplace=True)    # 전처리, 데이터의 특성 숙지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n {titanic_df.info()} \\n {titanic_df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n Sex 값 분포 : \\n {titanic_df['Sex'].value_counts()}\")\n",
    "print(f\"\\n Cabin 값 분포 : \\n {titanic_df['Cabin'].value_counts()}\")\n",
    "print(f\"\\n Embarked 값 분포 : \\n {titanic_df['Embarked'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[\"Cabin\"] = titanic_df[\"Cabin\"].str[:1]   # 첫글자만 따서 저장\n",
    "print(titanic_df[\"Cabin\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[\"Cabin\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupby([\"Sex\", \"Survived\"])[\"Survived\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Sex\", y=\"Survived\", data=titanic_df) # 비율로 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=titanic_df)\n",
    "# hue 는 각각 분할하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 age에 따라 구분값을 반환하는 함수 설정. DataFrame 의 apply lambda 식에 사용.\n",
    "def get_category(age) :\n",
    "    cat = ''\n",
    "    if age <= -1 : cat = \"Unknown\"\n",
    "    elif age <= 5 : cat = \"Baby\"\n",
    "    elif age <= 12 : cat = \"Child\"\n",
    "    elif age <= 18 : cat = \"Teenager\"\n",
    "    elif age <= 25 : cat = \"Student\"\n",
    "    elif age <= 35 : cat = \"Young Adult\"\n",
    "    elif age <= 60 : cat = \"Adult\"\n",
    "    else : cat = \"Elderly\"\n",
    "    \n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 막대그래프의 크기 figure를 더 크게 설정\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# X 축의 값을 순차적으로 표시하기 위한 설정  /  sns.barplot(order=)\n",
    "group_names = [\"Unknown\", \"Baby\", \"Child\", \"Teenager\", \"Student\", \"Young Adult\", \"Adult\", \"Elderly\"]\n",
    "\n",
    "# lambda 식에 위에서 생성한 get_category() 함수를 반환값으로 지정.\n",
    "# get_category(X)는 입력값으로 \"Age\" 컬럼값을 받아서 해당하는 cat 반환\n",
    "titanic_df[\"Age_cat\"] = titanic_df[\"Age\"].apply(lambda x : get_category(x))\n",
    "sns.barplot(x=\"Age_cat\", y=\"Survived\", hue=\"Sex\", data=titanic_df, order=group_names)\n",
    "titanic_df.drop(\"Age_cat\", axis=1, inplace=True)    # 한번 하고 없앰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트링으로 표현된 데이터들 넘버링  /  레이블 인코딩\n",
    "def encode_features(dataDF) :\n",
    "    features = [\"Cabin\", \"Sex\", \"Embarked\"]\n",
    "    for feature in features :\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "\n",
    "    return dataDF\n",
    "\n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리 과정을 함수로 리팩토링 → 학습 데이터에 적용하여 쉽게 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null 처리 함수\n",
    "def fillna(df) :\n",
    "    df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n",
    "    df[\"Cabin\"].fillna(\"N\", inplace=True)\n",
    "    df[\"Embarked\"].fillna(\"N\", inplace=True)\n",
    "    df[\"Fare\"].fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df) :\n",
    "    df.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 인코딩 수행\n",
    "def format_features(df) :\n",
    "    df[\"Cabin\"] = df[\"Cabin\"].str[:1]\n",
    "    features = [\"Cabin\", \"Sex\", \"Embarked\"]\n",
    "    for feature in features :\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에서 설정한 Data Processing 함수 호출\n",
    "def transform_features(df) :\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 만들기\n",
    "class DtPre :\n",
    "    \n",
    "    def __init__(self, df) :\n",
    "        self.df = df\n",
    "\n",
    "    def fillna(self) :\n",
    "        self.df[\"Age\"].fillna(self.df[\"Age\"].mean(), inplace=True)\n",
    "        self.df[\"Cabin\"].fillna(\"N\", inplace=True)\n",
    "        self.df[\"Embarked\"].fillna(\"N\", inplace=True)\n",
    "        self.df[\"Fare\"].fillna(0, inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    def drop_features(self) :\n",
    "        self.df.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis=1, inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    def format_features(self) :\n",
    "        self.df[\"Cabin\"] = self.df[\"Cabin\"].str[:1]\n",
    "        features = [\"Cabin\", \"Sex\", \"Embarked\"]\n",
    "        for feature in features :\n",
    "            le = LabelEncoder()\n",
    "            le = le.fit(self.df[feature])\n",
    "            self.df[feature] = le.transform(self.df[feature])\n",
    "        return self.df\n",
    "    \n",
    "    def transform_features(self) :\n",
    "        self.df = fillna(self.df)\n",
    "        self.df = drop_features(self.df)\n",
    "        self.df = format_features(self.df)\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv(\"./csv_data/titanic_train.csv\")\n",
    "y_titanic_df = titanic_df[\"Survived\"]   # 레이블 데이터 셋 추출\n",
    "X_titanic_df = titanic_df.drop(\"Survived\", axis=1)  # 피쳐 데이터 셋에서 레이블셋은 삭제\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df) # 만들어둔 전처리 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df,\n",
    "                                                    test_size=0.2, random_state=121)\n",
    "# 학습 데이터 셋 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 디시전 트리, 랜덤 포레스트, 로지스틱 회귀 모형 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 결정트리, Random Forest, 로지스틱 회귀를 위한 Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# 디시전 트리 모형으로 검증\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print(f\"DecisionTreeClassifier 정확도 : {accuracy_score(y_test, dt_pred) : .4f}\")\n",
    "\n",
    "# 랜덤 포레스트 모형으로 검증\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print(f\"RandomForestClassifier 정확도 : {accuracy_score(y_test, rf_pred) : .4f}\")\n",
    "\n",
    "# 로지스틱 모형으로 검증\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print(f\"LogisticRegression 정확도 : {accuracy_score(y_test, lr_pred) : .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFold 모형 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def exec_kfold(clf, folds=5) :\n",
    "    # 폴드 세트가 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위해 리스트 객체 생성\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "\n",
    "    # KFold 교차 검증 수행\n",
    "    for iter_count , (train_index, test_index) in enumerate(kfold.split(X_titanic_df)) :\n",
    "        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 형성\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "\n",
    "        # Classifier 검증\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(f\"교차검증 {iter_count} 정확도 : {accuracy : .4f}\")\n",
    "\n",
    "    # 5개 fold 에서의 평균 정확도 계산\n",
    "    mean_score = np.mean(scores)\n",
    "    print(f\"평균 정확도 : {mean_score:.4f}\")\n",
    "\n",
    "# exec_kfold 호출  /  위에서 설정한 디시전 트리 모형 가져옴\n",
    "exec_kfold(dt_clf, folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross_val_score 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 위에서 설정한 디시전 트리 모형에 대해 피쳐, 레이블 값 넣어서 5회 교차검증\n",
    "scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)\n",
    "for iter_count, accuracy in enumerate(scores) :\n",
    "    print(f\"교차검증 {iter_count} 정확도 : {accuracy:.4f}\")\n",
    "\n",
    "print(f\"평균 정확도 : {np.mean(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV 모형 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\"max_depth\" : [2, 3, 5, 10],      # 최대 깊이\n",
    "              \"min_samples_split\" : [2, 3, 5],  # 분할되기 위해 노드가 가져야 하는 최소 샘플 수\n",
    "              \"min_samples_leaf\" : [1, 5, 8]}   # 리프 노드가 가지고 있어야 할 최소 샘플 수\n",
    "\n",
    "# 위에서 미리 분할해 놓은 훈련 세트 / test_train_split\n",
    "grid_dclf = GridSearchCV(dt_clf, param_grid=parameters, scoring=\"accuracy\", cv=5)\n",
    "grid_dclf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"GridSearchCV 최적 하이퍼 파라미터 : {grid_dclf.best_params_}\")\n",
    "print(f\"GridSearchCV 최고 정확도 : {grid_dclf.best_score_:.4f}\")\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, dpredictions)\n",
    "print(f\"테스트 세트에서의 DecisionTreeClassifier 정확도 : {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d240ba0dc525c389faa33f5dcce5b4f32b6d6aa6d70d6d2dd929bd2b09ab69f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
