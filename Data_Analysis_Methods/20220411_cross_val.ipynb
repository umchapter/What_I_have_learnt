{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.cross_val_score\n",
    "* sklearn.model_selection.cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
    "* cv → 폴드 갯수\n",
    "* fit_params → 교차 검증으로 나온 최적 모형을 학습까지 시켜줌   \n",
    "dict\n",
    "* Markdown에서 줄바꿈 → 마지막 줄에서 세칸 이상 띄어쓰기 or Tab, 줄바꿈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 :  [0.98 0.94 0.98]\n",
      "평균 검증 정확도 :  0.9667\n"
     ]
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
    "scroes = cross_val_score(dt_clf, data, label, scoring = \"accuracy\", cv = 3)\n",
    "print(\"교차 검증별 정확도 : \", np.round(scroes, 4))\n",
    "print(\"평균 검증 정확도 : \", np.round(np.mean(scroes), 4))\n",
    "\n",
    "# KFold 에서 사용해야 하는 for문 없이 바로 결과 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSerchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에\n",
    "* class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 로딩하고 학습데이터와 테스트 데이터 분리\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
    "                                                    test_size = 0.2, random_state = 121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# parameter 들을 dictionary 형태로 설정\n",
    "parameters = {\"max_depth\" : [1,2,3], \"min_samples_split\":[2,3]}\n",
    "\n",
    "# 아래의 GridSearchCV 에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터 : {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도 :  0.9750\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# param_grid 의 하이퍼 파라미터들을 3개의 train, test_set_fold 로 \n",
    "# 나누어서 테스트 수행 설정.\n",
    "# refit = True 가 default 임. True 이면 가장 좋은 파라미터 설정으로 재학습 시킴.\n",
    "grid_dtree = GridSearchCV(dtree, param_grid = parameters, cv = 3, refit = True)\n",
    "\n",
    "# 붓꽃 Train 데이터로 param_grid 의 하이퍼 파라미터들을 순차적으로 학습/평가.\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV 결과 추출하여 DataFrame 으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[[\"params\", \"mean_test_score\", \"rank_test_score\",\n",
    "            \"split0_test_score\", \"split1_test_score\", \"split2_test_score\"]]\n",
    "print(f\"GridSearchCV 최적 파라미터 : {grid_dtree.best_params_}\")\n",
    "print(f\"GridSearchCV 최고 정확도 : {grid_dtree.best_score_ : .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도 0.9667\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV의 refit으로 이미 학습이 된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCV의best_estimator_는 이미 최적 하이퍼 파라미터로 학습이 됨\n",
    "pred = estimator.predict(X_test)\n",
    "print(f\"테스트 데이터 세트 정확도 {accuracy_score(y_test, pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7. , 3.2, 4.7, 1.4],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [7.1, 3. , 5.9, 2.1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 1, 0, 2, 0, 2, 2,\n",
       "       1, 1, 1, 1, 0, 0, 2, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.predict([[7. , 3.2, 4.7, 1.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.97142857, 0.02857143]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.predict_proba([[7. , 3.2, 4.7, 1.4]]) # 확률로 보여줌.\n",
    "                                            # 아마 가장 높은 확률 또는 90% 이상"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d240ba0dc525c389faa33f5dcce5b4f32b6d6aa6d70d6d2dd929bd2b09ab69f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
