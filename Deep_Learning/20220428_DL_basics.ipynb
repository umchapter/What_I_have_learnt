{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 기초\n",
    "===\n",
    "## 머신러닝\n",
    "* 데이터를 이용해 미지의 일을 예측하기 위해 만들어진 기법\n",
    "* 일반적인 프로그램이 데이터를 넣어서 답을 도출하는 과정이라면,   \n",
    "  데이터를 통해 규칙을 찾아내는 것이 머신러닝의 본질적 과정.\n",
    "## 학습(training)\n",
    "* 데이터가 입력되고 패턴이 분석되는 과정\n",
    "* 예시 :\n",
    "  1. 기존 환자 데이터를 입력(진료 기록과 사망·생존 여부)\n",
    "  2. 머신러닝으로 학습(규칙 발견)\n",
    "  3. 새로운 환자 예측\n",
    "* 랜덤포레스트, SVM, DeepLearning 등 려러가지 머신러닝 기법들이 존재\n",
    "## 예제를 통한 이해\n",
    "### 데이터 살펴보기 : ThoraricSurgery.csv\n",
    "* shape = (470, 18)\n",
    "* 속성(attribute), 특성(feature) X : 수술 환자 기록 17개 변수(종양 유형, 폐활량, 호흡곤란 여부 등)\n",
    "* 클래스 Y : 생존/사망\n",
    "* 딥러닝을 구동시키려면 '속성'만을 뽑아 데이터셋을 만들고, '클래스'를 담는 데이터셋을 또 따로 만들어 줘야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 0s 808us/step - loss: 0.6482 - accuracy: 0.8128\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 871us/step - loss: 0.4890 - accuracy: 0.8468\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.8511\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 630us/step - loss: 0.4863 - accuracy: 0.8489\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 699us/step - loss: 0.4430 - accuracy: 0.8532\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 701us/step - loss: 0.4303 - accuracy: 0.8532\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 754us/step - loss: 0.4421 - accuracy: 0.8511\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 619us/step - loss: 0.4363 - accuracy: 0.8489\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 701us/step - loss: 0.4165 - accuracy: 0.8489\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 677us/step - loss: 0.4317 - accuracy: 0.8489\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 759us/step - loss: 0.4458 - accuracy: 0.8489\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 641us/step - loss: 0.4384 - accuracy: 0.8532\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 737us/step - loss: 0.4651 - accuracy: 0.8532\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 652us/step - loss: 0.4475 - accuracy: 0.8319\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 631us/step - loss: 0.4934 - accuracy: 0.8255\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 739us/step - loss: 0.4472 - accuracy: 0.8447\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 972us/step - loss: 0.4747 - accuracy: 0.8383\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 695us/step - loss: 0.4488 - accuracy: 0.8468\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 587us/step - loss: 0.4407 - accuracy: 0.8511\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 652us/step - loss: 0.4380 - accuracy: 0.8511\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 630us/step - loss: 0.4331 - accuracy: 0.8532\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 652us/step - loss: 0.4242 - accuracy: 0.8511\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 630us/step - loss: 0.4183 - accuracy: 0.8532\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 774us/step - loss: 0.4303 - accuracy: 0.8489\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 629us/step - loss: 0.4246 - accuracy: 0.8511\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 685us/step - loss: 0.4335 - accuracy: 0.8532\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 739us/step - loss: 0.4492 - accuracy: 0.8383\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 674us/step - loss: 0.4241 - accuracy: 0.8532\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 676us/step - loss: 0.4212 - accuracy: 0.8532\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 627us/step - loss: 0.4136 - accuracy: 0.8511\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 713us/step - loss: 0.4389 - accuracy: 0.8511\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 594us/step - loss: 0.4188 - accuracy: 0.8553\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 788us/step - loss: 0.4428 - accuracy: 0.8532\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.4103 - accuracy: 0.8489\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 763us/step - loss: 0.4178 - accuracy: 0.8489\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 695us/step - loss: 0.4136 - accuracy: 0.8532\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 826us/step - loss: 0.4429 - accuracy: 0.8511\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 652us/step - loss: 0.4258 - accuracy: 0.8489\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 825us/step - loss: 0.4714 - accuracy: 0.8319\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 630us/step - loss: 0.4041 - accuracy: 0.8574\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 761us/step - loss: 0.4210 - accuracy: 0.8511\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.4418 - accuracy: 0.8447\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 708us/step - loss: 0.4096 - accuracy: 0.8511\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 652us/step - loss: 0.4032 - accuracy: 0.8511\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 732us/step - loss: 0.4067 - accuracy: 0.8532\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 674us/step - loss: 0.4030 - accuracy: 0.8532\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 804us/step - loss: 0.4132 - accuracy: 0.8447\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 634us/step - loss: 0.4026 - accuracy: 0.8532\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 652us/step - loss: 0.4082 - accuracy: 0.8511\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 739us/step - loss: 0.4097 - accuracy: 0.8511\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.4124 - accuracy: 0.8532\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 696us/step - loss: 0.3972 - accuracy: 0.8553\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 630us/step - loss: 0.4128 - accuracy: 0.8489\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 739us/step - loss: 0.4073 - accuracy: 0.8468\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.4110 - accuracy: 0.8532\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 817us/step - loss: 0.3921 - accuracy: 0.8532\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 687us/step - loss: 0.4091 - accuracy: 0.8532\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.3995 - accuracy: 0.8574\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 742us/step - loss: 0.3985 - accuracy: 0.8532\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 655us/step - loss: 0.3899 - accuracy: 0.8574\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.4041 - accuracy: 0.8553\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 762us/step - loss: 0.4246 - accuracy: 0.8468\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 656us/step - loss: 0.4068 - accuracy: 0.8532\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 804us/step - loss: 0.4318 - accuracy: 0.8511\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 717us/step - loss: 0.3902 - accuracy: 0.8553\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 720us/step - loss: 0.4312 - accuracy: 0.8511\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 696us/step - loss: 0.4164 - accuracy: 0.8489\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 722us/step - loss: 0.4090 - accuracy: 0.8511\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 696us/step - loss: 0.4020 - accuracy: 0.8511\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 587us/step - loss: 0.3986 - accuracy: 0.8574\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 804us/step - loss: 0.4027 - accuracy: 0.8511\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 587us/step - loss: 0.4196 - accuracy: 0.8340\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 696us/step - loss: 0.4019 - accuracy: 0.8532\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.3907 - accuracy: 0.8553\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 630us/step - loss: 0.3890 - accuracy: 0.8553\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 648us/step - loss: 0.4077 - accuracy: 0.8553\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 640us/step - loss: 0.4178 - accuracy: 0.8426\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 711us/step - loss: 0.4080 - accuracy: 0.8553\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 633us/step - loss: 0.4148 - accuracy: 0.8426\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 674us/step - loss: 0.4019 - accuracy: 0.8468\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 631us/step - loss: 0.4057 - accuracy: 0.8532\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 630us/step - loss: 0.4184 - accuracy: 0.8489\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 652us/step - loss: 0.3944 - accuracy: 0.8532\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.4345 - accuracy: 0.8468\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 631us/step - loss: 0.4050 - accuracy: 0.8489\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 827us/step - loss: 0.3922 - accuracy: 0.8489\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.3976 - accuracy: 0.8511\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 677us/step - loss: 0.3966 - accuracy: 0.8468\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 652us/step - loss: 0.3886 - accuracy: 0.8468\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 630us/step - loss: 0.3965 - accuracy: 0.8596\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 696us/step - loss: 0.4220 - accuracy: 0.8532\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 630us/step - loss: 0.4198 - accuracy: 0.8489\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 739us/step - loss: 0.3953 - accuracy: 0.8511\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.3871 - accuracy: 0.8489\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 696us/step - loss: 0.3864 - accuracy: 0.8574\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.4229 - accuracy: 0.8426\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 742us/step - loss: 0.4149 - accuracy: 0.8447\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 587us/step - loss: 0.3857 - accuracy: 0.8596\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 674us/step - loss: 0.4051 - accuracy: 0.8532\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 587us/step - loss: 0.3832 - accuracy: 0.8468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e80d410248>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 딥러닝을 구동하는 데 필요한 케라스 함수를 불러옴\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 필요한 라이브러리를 불러옴\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 실행할 때마다 같은 결과를 출력하기 위해 시드 설정\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 준비된 수술 환자 데이터를 불러들임\n",
    "Data_set = np.loadtxt(\"./csv_data/ThoraricSurgery.csv\", delimiter=\",\")\n",
    "\n",
    "# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
    "X = Data_set[:,0:17]\n",
    "Y = Data_set[:, 17]\n",
    "\n",
    "# 딥러닝 구조를 결정함(모델을 설정하고 실행하는 부분)\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=17, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# 딥러닝을 실행함\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* loss는 예측이 실패할 확률, accuracy는 예측이 성공할 확률.\n",
    "* 예측 성공률은 데이터를 분석해 데이터를 확장하거나, 딥러닝 구조를 적절하게 바꾸는 등의 노력으로 더 향상될 수 있음.\n",
    "* 뿐만 아니라 학습에 사용되지 않은 데이터를 따로 모아 테스트를 해보면서 예측 성공률이 저알로 가능한지를 확인하는 과정까지 거치게 됨.\n",
    "* 이러한 '최적화 과정'을 진행하려면 딥러닝의 구동 원리를 이해해야 함\n",
    "### 과정\n",
    "* Sequential()함수는 딥러닝의 구조를 한층한층 쉽게 쌓아올릴 수 있게 해 줌.\n",
    "* Sequential()함수를 선언하고 나서 model.add()함수를 사용해 필요한 층을 차례로 추가하면 됨.\n",
    "* 위의 코드에서 model.add()함수를 이용해 두 개의 층을 쌓아 올림.\n",
    "  * activation : 다음 층으로 어떻게 값을 넘길지 결정하는 부분.   \n",
    "  가장 많이 사용되는 함수 : relu() 함수, sigmoid() 함수.\n",
    "  * loss : 한 번 신경망이 실행될 때마다 오차 값을 추적하는 함수.\n",
    "  * optimizer : 오차를 어떻게 줄요 나갈지 정하는 함수.\n",
    "* 층의 개수는 데이터에 따라 결정.\n",
    "* 딥러닝의 구조와 층별 옵션을 정하고 나면 complie()함수를 이용해 이를 실행\n",
    "* 입력값이 네트워크 층을 거치면 예측값을 나오고, 이를 실제값과 비교해서 Loss Score를 계산한 후에 Optimizer를 통해 Weight를 업데이트 함.\n",
    "#### 기타 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "200/200 [==============================] - 0s 453us/step - loss: 1.6042 - mse: 1.6042\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 0s 457us/step - loss: 0.1634 - mse: 0.1634\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 0s 435us/step - loss: 0.1541 - mse: 0.1541\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 0s 477us/step - loss: 0.1425 - mse: 0.1425\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 0s 550us/step - loss: 0.1308 - mse: 0.1308\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 0s 468us/step - loss: 0.1250 - mse: 0.1250\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 0s 462us/step - loss: 0.1166 - mse: 0.1166\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 0s 489us/step - loss: 0.1131 - mse: 0.1131\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 0s 493us/step - loss: 0.1078 - mse: 0.1078\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 0s 458us/step - loss: 0.1036 - mse: 0.1036\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 0s 462us/step - loss: 0.1005 - mse: 0.1005\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 0s 468us/step - loss: 0.0998 - mse: 0.0998\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 0s 467us/step - loss: 0.0973 - mse: 0.0973\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 0s 452us/step - loss: 0.0953 - mse: 0.0953\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 0s 467us/step - loss: 0.0955 - mse: 0.0955\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 0s 453us/step - loss: 0.0928 - mse: 0.0928\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 0s 467us/step - loss: 0.0941 - mse: 0.0941\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 0s 471us/step - loss: 0.0936 - mse: 0.0936\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 0s 457us/step - loss: 0.0925 - mse: 0.0925\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 0s 452us/step - loss: 0.0903 - mse: 0.0903\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 0s 472us/step - loss: 0.0926 - mse: 0.0926\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 0s 437us/step - loss: 0.0911 - mse: 0.0911\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 0s 481us/step - loss: 0.0885 - mse: 0.0885\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 0s 458us/step - loss: 0.0906 - mse: 0.0906\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 0s 452us/step - loss: 0.0914 - mse: 0.0914\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 0s 437us/step - loss: 0.0910 - mse: 0.0910\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 0s 451us/step - loss: 0.0899 - mse: 0.0899\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 0s 447us/step - loss: 0.0912 - mse: 0.0912\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 0s 437us/step - loss: 0.0897 - mse: 0.0897\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 0s 451us/step - loss: 0.0912 - mse: 0.0912\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 가상적인 데이터 생성\n",
    "X = data = np.linspace(1, 2, 200)   # 시작값=1, 종료값=2, 개수=200\n",
    "y = X * 4 + np.random.randn(200) * 0.3  # x를 4배로 하고 편차 0.3 정도의 가우시간 잡음 추가\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation=\"linear\"))\n",
    "model.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mse\"])\n",
    "model.fit(X, y, batch_size=1, epochs=30)\n",
    "\n",
    "predict = model.predict(data)\n",
    "\n",
    "plt.plot(data, predict, \"b\", data, y, \"k.\")   #첫번째 그래프는 파란색 마커로\n",
    "plt.show()\n",
    "# 두번째 그래프는 검정색 \".\"으로 그린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 2.3x + 79.0\n"
     ]
    }
   ],
   "source": [
    "# 선형회귀식 도출\n",
    "import numpy as np\n",
    "\n",
    "X = [2,4,6,8]\n",
    "Y = [81, 93, 91, 97]\n",
    "\n",
    "mX = np.mean(X)\n",
    "mY = np.mean(Y)\n",
    "\n",
    "eX = X - mX\n",
    "eY = Y - mY\n",
    "\n",
    "slope = np.dot(eX, eY) / np.dot(eX, eX)\n",
    "\n",
    "b = mY - slope*mX\n",
    "\n",
    "print(f\"y = {slope}x + {b}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d87b42201e74ac320bc00dce267d44f5f134edfec9046f67f672f289707ff6a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
