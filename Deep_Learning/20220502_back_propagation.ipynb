{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오차 역전파\n",
    "===\n",
    "## 1. 오차 역전파의 개념\n",
    "* 신경망 내부의 가중치는 오차 역전파 방법을 사용해 수정함.\n",
    "  * 오차 역전파는 경사 하강법의 확장 개념.\n",
    "  * 가중치를 구하는 방법은 경사 하강법을 그대로 이용하면 됨.\n",
    "  * 임의의 가중치를 선언하고 결과값을 이용해 오차를 구한 뒤 이 오차가 최소인 지점으로 계속해서 조금씩 이동시킴(최적화 과정)   \n",
    "→ 오차 역전파(back propagation)\n",
    "  * 오차가 최소가 되는 점(미분했을 때 기울기가 0이 되는 지점)을 찾는 과정.\n",
    "* 역전파 알고리즘은 입력이 주어지면 순방향으로 계산하여 출력을 계산한 후에 실제 출력과 우리가 원하는 출력간의 오차를 계산함.\n",
    "* 이 오차를 역방향으로 전파하면서 오차를 줄이는 방향으로 가중치를 변경함.\n",
    "### 오차 역전파(back propagation) : 다층 퍼셉트론에서의 최적화 과정\n",
    "* 오차 역전파 구동방식은 다음과 같이 정리할 수 있음.\n",
    "    1. 임의의 초기 가중치 $w$를 준 뒤 결과 $y_{out}$를 계산함.\n",
    "    2. 계산 결과와 우리가 원하는 값 사이의 오차를 구함.\n",
    "    3. 경사 하강법을 이용해 바로 앞 가중치를 오차가 작아지는 방향으로 가중치 업데이트 함.\n",
    "    4. 위 과정을 더이상 오차가 줄어들지 않을 때까지 반복함.\n",
    "* '오차가 작아지는 방향으로 업데이트'는 의미는 미분 값이 0에 가까워지는 방향으로 나아간다는 말.\n",
    "* 즉, '기울기가 0이 되는 방향'으로 나아가야 하는데, 이 말은 가중치에서 기울기를 뺐을 때 가중치의 변화가 전혀 없는 상태를 말함.\n",
    "* 오차 역전파 : 가중치에서 기울기를 빼도 값의 변화가 없을 때까지 계속 가중치 수정 작업을 반복하는 것.\n",
    "$$W_{t+1} = W_t-\\frac{\\partial \\Epsilon}{\\partial W}$$\n",
    "* 새 가중치는 현 가중치에서 '가중치에 대한 기울기'를 뺀 값\n",
    "## 2. 코딩으로 확인하는 오차 역전파\n",
    "* 입력된 실제 값고 다층 퍼셉트론의 계산 결과를 비교하여 가중치를 역전파 방식으로 수정하는 알고리즘.\n",
    "  1. 환경 변수 지정 : 환경 변수에는 입력 값과 타깃 결과값이 포함된 데이터셋, 학습률 등이 포함되고 활성화 함수와 가중치 등도 선언되어야 함.\n",
    "  2. 신경망 실행 : 초깃값을 입력하여 활성화 함수와 가중치를 거쳐 결과값이 나오게 함.\n",
    "  3. 결과를 실제 값과 비교 : 오차를 측정함.\n",
    "  4. 역전파 실행 : 출력층과 은닉층의 가중치를 수정함.\n",
    "  5. 결과 출력."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
